{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Anomaly Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZFQQORCAcS",
        "colab_type": "text"
      },
      "source": [
        "# **Anomaly Detection [Outliers Detection]**\n",
        "\n",
        "**Introduction:**\n",
        "\n",
        "Anomaly detection is a process where you find out the list of outliers from your data. An outlier is a sample that has inconsistent data compared to other regular samples hence raises suspicion on their validity. The presence of outliers can also impact the performance of machine learning algorithms when performing supervised tasks. It can also interfere with data scaling which is a common data preprocessing step. As a part of this tutorial, we'll be discussing estimators available in scikit-learn which can help with identifying outliers from data.\n",
        "\n",
        "Below is a list of scikit-learn estimators which let us identify outliers present in data that we'll be discussing as a part of this tutorial:\n",
        "\n",
        " - KernelDensity\n",
        " - OneClassSVM\n",
        " = IsolationForest\n",
        " - LocalOutlierFactor\n",
        " \n",
        "We'll be explaining the usage of each one with various examples.\n",
        "\n",
        "Let’s start by importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD1Ko0KzD67p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/hussain0048/Machine-Learning.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beVu-1UqCAcU",
        "colab_type": "text"
      },
      "source": [
        "# **Importing necessary libraries** #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF03EKpuCAcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nhYP15aoCAcf",
        "colab_type": "text"
      },
      "source": [
        "# **Load Datasets**\n",
        "We'll start by loading two datasets that we'll be using for our explanation purpose.\n",
        "\n",
        "- Blobs Dataset - We have created a blobs dataset which has data of 3 clusters with 500 samples and 2 features per sample. We'll be using this dataset primarily for an explanation of sklearn estimators.\n",
        "- Digits Dataset - The second dataset that we'll load is digits dataset which has 1797 images of 0-9 digits. Each image is of size 8x8 which is flattened and kept as an array of size 64.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1wsGi52CAch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4012a260-58bf-4262-ef73-0b6769f2a53a"
      },
      "source": [
        " from sklearn.datasets import make_blobs\n",
        "\n",
        "X, Y = make_blobs(n_features=2, centers=3, n_samples=500,\n",
        "                  random_state=42)\n",
        "\n",
        "print(\"Dataset Size : \", X.shape, Y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Size :  (500, 2) (500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CVNbUV9G1dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "758bf179-c8d7-4bc3-d87f-da98c15f4f9b"
      },
      "source": [
        "with plt.style.context(\"ggplot\"):\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=\"tab:green\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbk3ih0aJwq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "087bde97-0cce-4d65-9469-8e910f178caa"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "X_digits, Y_digits = digits.data, digits.target\n",
        "\n",
        "print(\"Dataset Size : \", X_digits.shape, Y_digits.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Size :  (1797, 64) (1797,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4QYI2IoHWpL",
        "colab_type": "text"
      },
      "source": [
        "# 1- **KernelDensity** \n",
        "The KernelDensity estimator is available as a part of the kde module of the neighbors module of sklearn. It helps us measure kernel density of samples which can be then used to take out outliers. It uses KDTree or BallTree algorithm for kernel density estimation.\n",
        "\n",
        "Below is a list of important parameters of KernelDensity estimator:\n",
        "\n",
        "- algorithm - It accepts string value specifying which algorithm to use for kernel density estimation. We can specify one of the below values for this parameter.\n",
        "  - auto - Default.\n",
        "  - kd_tree\n",
        "  - ball_tree\n",
        "- kernel - It accepts string which let us specify which kernel to use for estimation. We can specify one of the below values.\n",
        "  - gaussian\n",
        "  - tophat\n",
        "  - epanechnikov\n",
        "  - exponential\n",
        "  - linear\n",
        "  - cosine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5gnX_D54aZ1",
        "colab_type": "text"
      },
      "source": [
        "## 1.1  Fitting Model to Data\n",
        "\n",
        "We'll first fit the KernelDensity estimator to our dataset using fit() method of it and then use it for finding out outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOA7lWQ7RRTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors.kde import KernelDensity\n",
        "# Estimate density with a Gaussian kernel density estimator\n",
        "kde = KernelDensity(kernel='gaussian')\n",
        "kde.fit(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTTQE9YJF1Q",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 - Calculate Log Density Evaluations for Each Sample\n",
        "The KernelDensity estimator has a method named score_samples() which accepts dataset and returns log density evaluations for each sample of data. We'll divide these values into 95% as valid data and 5% as outliers based on the output of score_samples() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TvqFi8-XCAcy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a00741e-83cb-4f8b-83da-8f83226cd145"
      },
      "source": [
        "kde_X = kde.score_samples(X)\n",
        "kde_X[:5]  # contains the log-likelihood of the data. The smaller it is the rarer is the sample"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.08546941, -5.33064441, -4.97908884, -4.18442233, -4.03465512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbM6eEUKAV-",
        "colab_type": "text"
      },
      "source": [
        "## 1.3-Dividing Dataset into Valid Samples and Outliers\n",
        "Below we are trying to find out quantiles value for 5% of total data. We'll use that value to divide data into outliers and valid samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-vctO1Kb3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats.mstats import mquantiles\n",
        "\n",
        "alpha_set = 0.95\n",
        "tau_kde = mquantiles(kde_X, 1. - alpha_set)\n",
        "\n",
        "tau_kde"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgyAtanLYfoT",
        "colab_type": "text"
      },
      "source": [
        "All the values in kde_X array which are less than tau_kde will be outliers and values greater than it will be qualified as valid samples. We'll try to find out indexes of samples that are outliers and valid. We'll then use these indexes to filter data to divide it into outliers and valid samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VblL63efYhza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outliers = np.argwhere(kde_X < tau_kde)\n",
        "outliers = outliers.flatten()\n",
        "X_outliers = X[outliers]\n",
        "\n",
        "normal_samples = np.argwhere(kde_X >= tau_kde)\n",
        "normal_samples = normal_samples.flatten()\n",
        "X_valid = X[normal_samples]\n",
        "\n",
        "print(\"Original Samples : \",X.shape[0])\n",
        "print(\"Number of Outliers : \", len(outliers))\n",
        "print(\"Number of Normal Samples : \", len(normal_samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8QNZN3CAdF",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 -Plot Outliers with Valid Samples for Comparison\n",
        "We have designed the method below named plot_outliers_with_valid_samples which takes as input valid samples and outliers and then plots them using different colors to differentiate between them. The figure will give a better idea about the performance of KernelDensity.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBdXxiHLfLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_outliers_with_valid_samples(X_valid, X_outliers):\n",
        "    with plt.style.context((\"seaborn\", \"ggplot\")):\n",
        "        plt.scatter(X_valid[:, 0], X_valid[:, 1], c=\"tab:green\", label=\"Valid Samples\")\n",
        "        plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c=\"tab:red\", label=\"Outliers\")\n",
        "        plt.legend(loc=\"best\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkXFMVZP76K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_outliers_with_valid_samples(X_valid, X_outliers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WNB53OY8IfG",
        "colab_type": "text"
      },
      "source": [
        "#2 OneClassSVM \n",
        "\n",
        "The OneClassSVM estimator is available as a part of svm module of sklearn. It's based on the SVM algorithm which is used behind the scene to make a decision about the sample is outlier or not.\n",
        "\n",
        "Below is a list of important parameters of OneClasSVM which can be tweaked further to get better results:\n",
        "\n",
        " - kernel - It specifies the kernel type to be used for SVM. It accepts one of the below values as input.\n",
        "   - linear\n",
        "   - poly\n",
        "   - rbf\n",
        "   - sigmoid\n",
        "   - precomputed\n",
        " - degree - It accepts integer specifying degree of polynomial kernel (kernel='poly'). It's ignored when other kernels are used.\n",
        " - gamma - It specifies kernel coefficient to use for rbf, poly and sigmoid kernels. It accepts one of the below string or float as input.\n",
        "  - scale - It uses 1 / (n_features * X.var()) as value of gamma.\n",
        "  - auto - Default. It uses 1 / n_features as the value of gamma.\n",
        " - nu - It accepts float value in the range (0, 1] specifying upper bound on the fraction of training errors and lower bound on the fraction of support vectors.\n",
        " - cache_size - It specifies kernel cache size in MB. It accepts integer values as input. The default value is 200 MB. It’s recommended using more value for bigger datasets for better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR5OSQxWrk6B",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Fitting Model to Data¶\n",
        "We'll now fit OneClassSVM to our Gaussian blobs dataset. We'll then use the trained model to make predictions about samples to let us know whether the sample is an outlier or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_ykAt_v8egH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "nu = 0.05  # theory says it should be an upper bound of the fraction of outliers\n",
        "ocsvm = OneClassSVM(kernel='rbf', gamma=0.05, nu=nu)\n",
        "ocsvm.fit(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdpTOYOlCAdP",
        "colab_type": "text"
      },
      "source": [
        "## 2.2-Predict Sample Class (Outlier vs Normal)¶\n",
        "\n",
        "OneClassSVM provides predict() method which accepts samples and returns array consisting of values 1 or -1. Here 1 represents a valid sample and -1 represents an outlier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5uHKjQWZ0WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = ocsvm.predict(X)\n",
        "preds[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTe0Qqi3CAeA",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 - Dividing Dataset into Valid Samples and Outliers\n",
        "\n",
        "We'll now filter original data and divide it into two categories.\n",
        "\n",
        "- Valid Samples\n",
        "= Outliers\n",
        "We'll also print the size of samples that were considered outliers by model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq4Ho1l8Ksjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_outliers = X[preds == -1]\n",
        "X_valid = X[preds != -1]\n",
        "\n",
        "print(\"Original Samples : \",X.shape[0])\n",
        "print(\"Number of Outliers : \", X_outliers.shape[0])\n",
        "print(\"Number of Normal Samples : \", X_valid.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VwPfoQSS4Av",
        "colab_type": "text"
      },
      "source": [
        "## 2.4 Plot Outliers with Valid Samples for Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bB5XBn5tOFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_outliers_with_valid_samples(X_valid, X_outliers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrZx-6XeziR0",
        "colab_type": "text"
      },
      "source": [
        "## 2.5 Important Attributes and methods of OneClassSVM\n",
        "Below is a list of important attributes and methods of OneClassSVM which can be used once the model is trained to get meaningful insights.\n",
        "\n",
        "- support_ - It returns indices of support vectors.\n",
        "- support_vectors_ - It returns actual support vectors of SVM.\n",
        "dual_coef_ - It represents coefficients of support vectors in decision function.\n",
        "- coef_ - It returns an array of the same size as that of features in dataset representing weights assigned to each feature. It works only when kernel linear is used.\n",
        "- intercept_ - It returns single float value representing intercept when using linear kernel.\n",
        "- decision_function(X) - It accepts dataset as input and returns signed distance for each sample of data. If the distance is positive then the sample is valid and outlier if negative.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q87nKz4zxr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Support Indices : \",ocsvm.support_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPUBga2Atw83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Support Vector Sizes : \", ocsvm.support_vectors_.shape)\n",
        "ocsvm.support_vectors_[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sgDFaxjt9lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Dual Coef Size \", ocsvm.dual_coef_.shape)\n",
        "ocsvm.dual_coef_[0][:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyTJvAmAuL11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ocsvm_X = ocsvm.decision_function(X)\n",
        "\n",
        "X_outliers = X[ocsvm_X < 0]\n",
        "X_valid = X[ocsvm_X > 0]\n",
        "\n",
        "print(\"Number of Outliers : \", X_outliers.shape[0])\n",
        "print(\"Number of Normal Samples : \", X_valid.shape[0])\n",
        "\n",
        "ocsvm_X[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYtLLnosvWLU",
        "colab_type": "text"
      },
      "source": [
        "We can notice from the above output that decision_function() can be used to find out outliers as well and it'll return the same indexes as predict() for samples which are outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sq0XpVN0UZ7",
        "colab_type": "text"
      },
      "source": [
        "## 2.6-Trying OneClassSVM on DIGITS Dataset.\n",
        "We are now trying OneClassSVM on the digits dataset. We'll fit it to digits data and then use it to predict whether a sample is an outlier or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFeG8p_Sv2JX",
        "colab_type": "text"
      },
      "source": [
        "## 2.7 Fitting Model to Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ2nyHRV0dnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " nu = 0.05  # theory says it should be an upper bound of the fraction of outliers\n",
        "ocsvm = OneClassSVM(kernel='rbf', gamma=0.05, nu=nu)\n",
        "ocsvm.fit(X_digits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUnd-y071Epv",
        "colab_type": "text"
      },
      "source": [
        "## 2.8- Predict Sample Class (Outlier vs Normal)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsBaFnzd1U_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = ocsvm.predict(X_digits)\n",
        "preds[:10]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Gq2A7BCAeX",
        "colab_type": "text"
      },
      "source": [
        "## 2.9 -Dividing Dataset into Valid Samples and Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS5rUYkYesAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_outliers = X_digits[preds == -1]\n",
        "X_valid = X_digits[preds != -1]\n",
        "print(\"Original Samples : \",X_digits.shape[0])\n",
        "print(\"Number of Outliers : \", X_outliers.shape[0])\n",
        "print(\"Number of Normal Samples : \", X_valid.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWCpBVwViJPO",
        "colab_type": "text"
      },
      "source": [
        "## 2.10. Plot Few Valid and Outlier Samples \n",
        "We'll now plot a few valid samples and few outliers for digits dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgxfwrTXJ8xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_few_outliers(X_outliers):\n",
        "    outliers = []\n",
        "    for x in X_outliers[:10]:\n",
        "        outliers.append(x.reshape(8,8))\n",
        "\n",
        "    fig = plt.figure(figsize=(10,4))\n",
        "    plt.imshow(np.hstack(outliers), cmap=\"Blues\");\n",
        "\n",
        "plot_few_outliers(X_outliers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yipu36tIKI3a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "35c256ad-5ee0-40c4-8a64-0e6ce5d39d6d"
      },
      "source": [
        "def plot_few_valid_samples(X_valid):\n",
        "    valid_samples = []\n",
        "    for x in X_valid[:10]:\n",
        "        valid_samples.append(x.reshape(8,8))\n",
        "\n",
        "    fig = plt.figure(figsize=(10,4))\n",
        "    plt.imshow(np.hstack(valid_samples), cmap=\"Blues\");\n",
        "\n",
        "plot_few_valid_samples(X_valid)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6as5LRNgjTng",
        "colab_type": "text"
      },
      "source": [
        "#3- IsolationForest\n",
        "\n",
        "IsolationForest is another estimator available as a part of the ensemble module of sklearn which can be used for anomaly detection. It measures the anomaly scores for each sample based on the isolation forest algorithm. IsolationForest isolates samples by randomly selecting a feature of the sample and then randomly selecting a split value between maximum and minimum of the selected sample. It recursively partitions samples based on features that can be represented as tree structures. This results in a number of splittings required to isolate the sample are equal to path length in a tree. This path length can be used to make a decision about the sample being normal or an outlier. Outliers generally have short path lengths.\n",
        "\n",
        "Below is a list of important attributes of IsolationForest which can be tweaked for better performance:\n",
        "\n",
        "n_estimators - It accepts integer representing number of base estimators to use for IsolationForest. default=100\n",
        "max_samples - It represents a number of samples to draw from the dataset to train each base estimator. It accepts the below-mentioned values.\n",
        "auto - Default. It takes min(256, n_samples) as value of max_samples.\n",
        "int - We can specify integer value specifying the number of samples.\n",
        "float - We can specify float value between 0-1 and it'll take that fraction of samples from original data for training.\n",
        "contamination - It specifies the number of outliers in the dataset. It accepts one of the below values as input.\n",
        "auto - Default. The value for the number of outliers from the original dataset is determined automatically.\n",
        "float - It let us specify float value between 0-0.5 and set that many proportions of samples as outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "yN3QOkmDCAed",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 - Fitting Model to Data\n",
        "We'll now fit IsolationForest to our Gaussian blobs dataset. We'll then use the trained model to make predictions about samples to let us know whether sample is an outlier or not.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKMoGy7D4KXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "iforest = IsolationForest(n_estimators=300, contamination=0.05)\n",
        "iforest.fit(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6HAiq04ZKr",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Predict Sample Class (Outlier vs Normal)¶\n",
        "IsolationForest provides predict() method which accepts samples and returns array consisting of values 1 or -1. Here 1 represents a valid sample and -1 represents an outlier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woRGjqgH4lTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = iforest.predict(X)\n",
        "preds[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xH8Qq6J72il",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 -Dividing Dataset into Valid Samples and Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcudcn3rgf7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_outliers = X[preds == -1]\n",
        "X_valid = X[preds != -1]\n",
        "print(\"Original Samples : \",X.shape[0])\n",
        "print(\"Number of Outliers : \", X_outliers.shape[0])\n",
        "print(\"Number of Normal Samples : \", X_valid.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J75Rv0fr8qWA",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 Plot Outliers with Valid Samples for Comparison¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDoYPVl48x_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_outliers_with_valid_samples(X_valid, X_outliers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Ubl4dFR1IG",
        "colab_type": "text"
      },
      "source": [
        "## 3.5 Important Attributes and Methods of IsolationForest\n",
        "\n",
        "Below is a list of important attributes and methods of IsolationForest which can be used once the model is trained to get meaningful insights.\n",
        "\n",
        "- estimators_ - It returns a list of base estimators that were trained during training.\n",
        "- threshold_ - It returns threshold value which will be used to make a decision about the sample is an outlier or not.\n",
        "- decision_function(X) - It takes dataset as input and returns average anomaly score for each feature. We can then divide the dataset into normal and outliers based on the threshold_ attribute and these parameter values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UlaNus5S00W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iforest.estimators_[:2]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7szrlQiBNOnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iforest.threshold_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCmBoS8CNX5l",
        "colab_type": "text"
      },
      "source": [
        "Below we are splitting the dataset into valid samples and outliers using output of decision_function() and threshold_ value found out after training model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE8tUADZNax8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = iforest.decision_function(X)\n",
        "\n",
        "outliers  = X[results < iforest.threshold_]\n",
        "valid_samples = X[results >= iforest.threshold_]\n",
        "\n",
        "print(\"Number of Outliers : \", outliers.shape[0])\n",
        "print(\"Number of Valid Samples : \", valid_samples.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2MOQ4EQSOR3",
        "colab_type": "text"
      },
      "source": [
        "##3.6.Trying IsolationForest on DIGITS Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH3RPskMSFz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(Y_test, complement_nb_grid.best_estimator_.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Bpx7DCS_Hg",
        "colab_type": "text"
      },
      "source": [
        "##3.7 Fitting Default Model To Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRZyu778bBmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iforest = IsolationForest(n_estimators=300, contamination=0.05)\n",
        "iforest.fit(X_digits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na4QkhBbbKUT",
        "colab_type": "text"
      },
      "source": [
        "##3.8 Predict Sample Class (Outlier vs Normal)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4jiDFJnbJAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = iforest.predict(X_digits)\n",
        "preds[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZfpXMFLbiDQ",
        "colab_type": "text"
      },
      "source": [
        "##3.9 Dividing Dataset into Valid Samples and Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXpM8bIebn7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "130ea0e3-7140-40a1-aa62-6e79a2b710f9"
      },
      "source": [
        " X_outliers = X_digits[preds == -1]\n",
        "X_valid = X_digits[preds != -1]\n",
        "\n",
        "print(\"Original Samples : \",X_digits.shape[0])\n",
        "print(\"Number of Outliers : \", X_outliers.shape[0])\n",
        "print(\"Number of Normal Samples : \", X_valid.shape[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Samples :  1797\n",
            "Number of Outliers :  90\n",
            "Number of Normal Samples :  1707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkHO3kcibyVR",
        "colab_type": "text"
      },
      "source": [
        "## 3.10 Plot Few Valid and Outlier Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJthSM_lcDZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_few_outliers(X_outliers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3NMSeXacQf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_few_valid_samples(X_valid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOU8Vi0BccAJ",
        "colab_type": "text"
      },
      "source": [
        "# 4-LocalOutlierFactor ¶\n",
        "\n",
        "The LocalOutlierFactor estimator is available as the neighbors module of sklearn which is another estimator that lets us find out whether a sample from the dataset is an outlier or not. It measures the local density of a sample with respect to its neighbors. Based on a comparison between the local density of the sample and its neighbors, the decision is made whether the sample is an outlier or not.\n",
        "\n",
        "Below is a list of important attributes of IsolationForest which can be tweaked for better performance:\n",
        "\n",
        "- n_neighbors - It accepts integer value specifying the number of neighbors to use for deciding whether to consider sample outlier or not.\n",
        "- algorithm - It accepts string value specifying the algorithm to use for nearest neighbors. Below is a list of possible values.\n",
        " - auto - Default\n",
        " - kd_tree\n",
        " - ball_tree\n",
        "`- brute\n",
        "- metric - It accepts string or callable function specifying metric to use for distance computation. The default value is minkowski for this parameter. Please refer sklearn docs for list of possible metrics for this parameter.\n",
        "- contamination - It specifies amount of outliers in the dataset. It accepts one of the below values as input.\n",
        "auto - Default. The value for the number of outliers from the original dataset is determined automatically.\n",
        "float - It let us specify float value between 0-0.5 and set that many proportions of samples as outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLbupXO4mHSk",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 Fitting a model \n",
        "We'll now fit LocalOutlierFactor to our Gaussian blobs dataset. We'll then use the trained model to make predictions about samples to let us know whether the sample is an outlier or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH7k634FcuyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "lof = LocalOutlierFactor()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdpo2iWxdBaY",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Predict Sample Class (Outlier vs Normal)¶\n",
        "\n",
        "LocalOutlierFactor provides predict() method which accepts samples and returns array consisting of values 1 or -1. Here 1 represents a valid sample and -1 represents an outlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPRXvkRfdHcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = lof.fit_predict(X)\n",
        "preds[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndMJgpqWmqdv",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Dividing Dataset into Valid Samples and Outliers# "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXsmpuJLmyVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_outliers = X[preds == -1]\n",
        "X_valid = X[preds != -1]\n",
        "print(\"Original Samples : \",X.shape[0])\n",
        "print(\"Number of Outliers : \", X_outliers.shape[0])\n",
        "print(\"Number of Normal Samples : \", X_valid.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvuOCngrm6BE",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 Plot Outliers with Valid Samples for Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z12dBlIim_z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_outliers_with_valid_samples(X_valid, X_outliers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9fj3uyCnJPM",
        "colab_type": "text"
      },
      "source": [
        "## 4.5 Important Attributes and Methods of LocalOutlierFactor\n",
        "Below is a list of important attributes and methods of LocalOutlierFactor which can be used once the model is trained to get meaningful insights.\n",
        "\n",
        "- negative_outlier_factor_ - It represents the opposite of LOF of data samples. The higher the value for the sample, the more normal it is.\n",
        "- offset_ - It specifies a value which can be used as a threshold to divide samples into normal or outlier based on negative_outlier_factor_ values of samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S91-mf_2nYOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lof.offset_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfBiycL6nd6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Negative Outlier Factor Shape : \", lof.negative_outlier_factor_.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH72gEvtnkdO",
        "colab_type": "text"
      },
      "source": [
        "Below we are dividing the dataset into normal and outliers based on offset_ and negative_outlier_factor_ parameters of LocalOutlierFactor. It gives the same result as that of predict()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZxyq-ZMnf6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ca63034-6fc7-44a0-f8df-926a51503740"
      },
      "source": [
        "outliers  = X[lof.negative_outlier_factor_ < lof.offset_]\n",
        "valid_samples = X[lof.negative_outlier_factor_ >= lof.offset_]\n",
        "\n",
        "print(\"Number of Outliers : \", outliers.shape[0])\n",
        "print(\"Number of Valid Samples : \", valid_samples.shape[0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Outliers :  30\n",
            "Number of Valid Samples :  470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkTxtY6LntT3",
        "colab_type": "text"
      },
      "source": [
        "## 4.6 Trying LocalOutlierFactor on DIGITS Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbfMI870n2BP",
        "colab_type": "text"
      },
      "source": [
        "## 4.7  Fitting Model to Data¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQzX-6Ozn8N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lof = LocalOutlierFactor(n_neighbors=100)\n",
        "\n",
        "preds = lof.fit_predict(X_digits)\n",
        "preds[:10]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DQxvm18oB7s",
        "colab_type": "text"
      },
      "source": [
        "## 4.8 Dividing Dataset into Valid Samples and Outliers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRee_6ZBoJf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_outliers = X_digits[preds == -1]\n",
        "X_valid = X_digits[preds != -1]\n",
        "\n",
        "print(\"Original Samples : \",X_digits.shape[0])\n",
        "print(\"Number of Outliers : \", X_outliers.shape[0])\n",
        "print(\"Number of Normal Samples : \", X_valid.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAjpEo4voWuA",
        "colab_type": "text"
      },
      "source": [
        "##4.9 Plot Few Valid and Outlier Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpNIPBc9oTCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_few_outliers(X_outliers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO1_w4A-oniv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_few_valid_samples(X_valid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7uTbEWCAei",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "Scikit-Learn - Anomaly Detection [Outliers Detection]\n",
        "https://coderzcolumn.com/tutorials/machine-learning/scikit-learn-sklearn-anomaly-detection-outliers-detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LvqfD4BCAei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}