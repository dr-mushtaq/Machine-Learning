{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Machine-Learning/blob/master/Sklearn/supervised%20algorithm/Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZFQQORCAcS",
        "colab_type": "text"
      },
      "source": [
        "# Neural network (NN) \n",
        "\n",
        "**Introduction:**\n",
        "\n",
        "The most common type of neural network referred to as Multi-Layer Perceptron (MLP) is a function that maps input to output. MLP has a single input layer and a single output layer. In between, there can be one or more hidden layers. The input layer has the same set of neurons as that of features. Hidden layers can have more than one neuron as well. Each neuron is a linear function to which activation function is applied to solve complex problems. The output from each layer is given as input to all neurons of the next layers.\n",
        "\n",
        "**sklearn provides 2 estimators for classification and regression problems respectively.:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-HyuLjXeIsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/hussain0048/Machine-Learning.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beVu-1UqCAcU",
        "colab_type": "text"
      },
      "source": [
        "## 1 - Importing necessary libraries ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF03EKpuCAcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(precision=2)\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nhYP15aoCAcf",
        "colab_type": "text"
      },
      "source": [
        "## 2 - Load Datasets ##\n",
        "\n",
        "We'll be loading below mentioned two for our purpose.:\n",
        "    - **Digits Dataset**: We'll be using digits dataset which has images of size 8x8 for digits 0-9. We'll use digits data for classification tasks below.\n",
        "    - a test set of m_test images labeled as cat or non-cat\n",
        "    - **Housing Dataset**: We'll be using the Boston housing dataset which has information about various house properties like average no of rooms, per capita crime rate in town, etc. We'll be using it for regression task.\n",
        "\n",
        "Sklearn provides both of this dataset as a part of the datasets module. We can load them by calling load_digits() and load_boston() methods. It returns dictionary-like object BUNCH which can be used to retrieve features and target.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1wsGi52CAch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99401f9c-0f11-4711-9752-b7263865e339"
      },
      "source": [
        "# Loading the data \n",
        "from sklearn.datasets import load_digits, load_boston\n",
        "digits = load_digits()\n",
        "X_digits, Y_digits = digits.data, digits.target\n",
        "print('Dataset Sizes : ', X_digits.shape, Y_digits.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Sizes :  (1797, 64) (1797,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkKgfaIDGPyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()\n",
        "X_boston, Y_boston = boston.data, boston.target\n",
        "print('Dataset Sizes : ', X_boston.shape, Y_boston.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNlfErRUCAcp",
        "colab_type": "text"
      },
      "source": [
        "**MLPClassifier** \n",
        "\n",
        "MLPClassifier is an estimator available as a part of the neural_network module of sklearn for performing classification tasks using a multi-layer perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4QYI2IoHWpL",
        "colab_type": "text"
      },
      "source": [
        "## 3 - Splitting Data Into Train/Test Sets ##\n",
        "We'll split the dataset into two parts:\n",
        "- Training data which will be used for the training model.\n",
        "\n",
        "- Test data against which accuracy of the trained model will be checked.\n",
        "\n",
        "train_test_split function of model_selection module of sklearn will help us split data into two sets with 80% for training and 20% for test purposes. We are also using seed(random_state=123) with train_test_split so that we always get the same split and can reproduce results in the future as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9JGZRKCCAcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_digits, Y_digits, train_size=0.80, test_size=0.20, stratify=Y_digits, random_state=123)\n",
        "print('Train/Test Sizes : ', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTTQE9YJF1Q",
        "colab_type": "text"
      },
      "source": [
        "##4- Fitting Default Model To Train Data##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWb05_-aCAcx",
        "colab_type": "text"
      },
      "source": [
        " We'll first fit the MLPClassifier model with default parameters to our train data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TvqFi8-XCAcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp_classifier  = MLPClassifier(random_state=123)\n",
        "mlp_classifier.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAauC4nXCAc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set_x = train_set_x_flatten/255.\n",
        "test_set_x = test_set_x_flatten/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbM6eEUKAV-",
        "colab_type": "text"
      },
      "source": [
        "## 5-Evaluating Trained Model On Test Data ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQSLt44LCAdE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Almost all models in Scikit-Learn API provides predict() method which can be used to predict target variable on Test Set passed to it.:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-vctO1Kb3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_preds = mlp_classifier.predict(X_test)\n",
        "print(Y_preds[:15])\n",
        "print(Y_test[:15])\n",
        "print('Test Accuracy : %.3f'%mlp_classifier.score(X_test, Y_test)) ## Score method also evaluates accuracy for classification models.\n",
        "print('Training Accuracy : %.3f'%mlp_classifier.score(X_train, Y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8QNZN3CAdF",
        "colab_type": "text"
      },
      "source": [
        "## 6 - Plotting Confusion Matrix ##\n",
        "\n",
        "Below we have created a method named plot_confusion_matrix() which accepts original labels of data and predicted labels by model. It then plots a confusion matrix using matplotlib. We'll be reusing the same method for plotting the confusion matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBdXxiHLfLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(Y_test, Y_preds):\n",
        "    conf_mat = confusion_matrix(Y_test, Y_preds)\n",
        "    #print(conf_mat)\n",
        "    fig = plt.figure(figsize=(6,6))\n",
        "    plt.matshow(conf_mat, cmap=plt.cm.Blues, fignum=1)\n",
        "    plt.yticks(range(10), range(10))\n",
        "    plt.xticks(range(10), range(10))\n",
        "    plt.colorbar();\n",
        "    for i in range(10):\n",
        "        for j in range(10):\n",
        "            plt.text(i-0.2,j+0.1, str(conf_mat[j, i]), color='tab:red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkP2MD5FLmmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(Y_test, mlp_classifier.predict(X_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g78HCuLVCAdG",
        "colab_type": "text"
      },
      "source": [
        "## 7 - Important Attributes of MLPClassifier## \n",
        "\n",
        "Below is a list of important attributes available with an MLPClassifier which can provide meaningful insights once the model is trained.:\n",
        "1. loss_ - It returns loss after the training process has completed.\n",
        "2. coefs_ - It returns an array of length n_layers-1 where each element represents weights associated with layer i.\n",
        "3. intercepts_ - It returns an array of length n_layers-1 where each element represents intercept associated with layer i's perceptrons.\n",
        "4. n_iter_ - The number of iterations for which estimator ran.\n",
        "5. out_activation_ - It returns name of output layer activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTAYjq6JOpj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Loss : \", mlp_classifier.loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA_rf8zIO4hI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of Coefs : \", len(mlp_classifier.coefs_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R0zQ4BHPKBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of Intercepts : \", len(mlp_classifier.intercepts_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mQYgWuyPRbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of Iterations for Which Estimator Ran : \", mlp_classifier.n_iter_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwOLIUoIPjY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Name of Output Layer Activation Function : \", mlp_classifier.out_activation_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdpTOYOlCAdP",
        "colab_type": "text"
      },
      "source": [
        "## 8- Finetuning Model By Doing Grid Search On Various Hyperparameters\n",
        "\n",
        "Below is a list of common hyperparameters that needs tuning for getting the best fit for our data. We'll try various hyperparameters settings to various splits of train/test data to find out best fit which will have almost the same accuracy for both train & test dataset or have quite less difference between accuracy.\n",
        "1. hidden_layer_sizes - It accepts tuple of integer specifying sizes of hidden layers in multi layer perceptrons. According to size of tuple, that many perceptrons will be created per hidden layer. default=(100,)\n",
        "2. activation - It specifies activation function for hidden layers. It accepts one of below strings as input. default=relu.\n",
        "  - identity' - No Activation. f(x) = x.\n",
        "  - 'logistic' - Logistic Sigmoid Function. f(x) = 1 / (1 + exp(-x))\n",
        "  - 'tanh' - Hyperbolic tangent function. f(x) = tanh(x)\n",
        "  - 'relu' - Rectified Linear Unit function. f(x) = max(0, x)\n",
        "3. solver - It accepts one of below strings specifying which optimization solver to use for updating weights of neural network hidden layer perceptrons. default='adam'\n",
        "identity' - No Activation. f(x) = x.\n",
        "  - 'lbfgs\n",
        "  - 'sgd'\n",
        "  - 'adam'\n",
        "4. learning_rate - It specifies learning rate schedule to be used for training. It accepts one of below strings as value and only applicable when solver='sgd' \n",
        "  \n",
        "  -'constant' - Keeps learning rate constant through a learning process which was set in learning_rate_init.\n",
        "  - 'invscaling' - It gradually decreases learning rate. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
        "  - 'adaptive' - It keeps learning rate constant as long as loss is decreasing or score is improving. If consecutive epochs fails in decreasing loss according to tol parameter and early_stopping is on, then it divides current learning rate by 5.\n",
        "5. batch_size - It accepts integer value specifying size of batch to use for dataset. default='auto'. The default auto batch size will set batch size to min(200, n_samples). It accepts one of below strings as value and only applicable when solver='sgd'\n",
        "6. tol - It accepts float values specifying threshold for optimization. When training loss or score is not improved by at least tol for n_iter_no_change iterations, then optimization ends if learning_rate is constant else it decreases learning rate if learning_rate is adaptive. default=0.0001 It accepts one of below strings as value and only applicable when solver='sgd'\n",
        "7. alpha - It specifies L2 penalty coefficient to be applied to perceptrons. default=0.0001\n",
        "8. momentum - It specifies momentum to be used for gradient descent and accepts float value between 0-1. It's applicable when solver is sgd.\n",
        "9. early_stopping - It accepts boolean value specifying whether to stop training if training score/loss is not improving. default=False\n",
        "10. validation_fraction - It accepts float value between 0-1 specifying amount of training data to keep aside if early_stopping is set.default=0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_GstlsrCAdc",
        "colab_type": "text"
      },
      "source": [
        "##9-GridSearchCV\n",
        "\n",
        "\n",
        "It's a wrapper class provided by sklearn which loops through all parameters provided as params_grid parameter with a number of cross-validation folds provided as cv parameter, evaluates model performance on all combinations and stores all results in cv_results_ attribute. It also stores model which performs best in all cross-validation folds in best_estimator_ attribute and best score in best_score_ attribute.\n",
        "\n",
        "We'll below try various values for the above-mentioned hyperparameters to find the best estimator for our dataset by splitting data into 5-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1DF698ECAdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {'activation': ['relu', 'tanh', 'logistic', 'identity'],\n",
        "          'hidden_layer_sizes': [(100,), (50,100,), (50,75,100,)],\n",
        "          'solver': ['adam', 'sgd', 'lbfgs'],\n",
        "          'learning_rate' : ['constant', 'adaptive', 'invscaling']\n",
        "         }\n",
        "\n",
        "mlp_classif_grid = GridSearchCV(MLPClassifier(random_state=123), param_grid=params, n_jobs=-1, cv=5, verbose=5)\n",
        "mlp_classif_grid.fit(X_train,Y_train)\n",
        "\n",
        "print('Train Accuracy : %.3f'%mlp_classif_grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test Accuracy : %.3f'%mlp_classif_grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best Accuracy Through Grid Search : %.3f'%mlp_classif_grid.best_score_)\n",
        "print('Best Parameters : ',mlp_classif_grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTe0Qqi3CAeA",
        "colab_type": "text"
      },
      "source": [
        "## 10 - Plotting Confusion Matrix##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm-21jozCAeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(Y_test, mlp_classif_grid.best_estimator_.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Gq2A7BCAeX",
        "colab_type": "text"
      },
      "source": [
        "## 11 - MLPRegressor ##\n",
        "\n",
        " MLPRegressor is an estimator available as a part of the neural_network module of sklearn for performing regression tasks using a multi-layer perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWCpBVwViJPO",
        "colab_type": "text"
      },
      "source": [
        "### 11.1 Splitting Data Into Train/Test Set\n",
        "We'll split the dataset into two parts:\n",
        "\n",
        "  -Train data(80%) which will be used for the training model.\n",
        "  -Test data(20%) against which accuracy of the trained model will be checked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKE53swWipAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X_boston, Y_boston, train_size=0.80, test_size=0.20, random_state=123)\n",
        "print('Train/Test Sizes : ', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otTssvGBi3Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "mlp_regressor  = MLPRegressor(random_state=123)\n",
        "mlp_regressor.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSs1A6O6jAJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_preds = mlp_regressor.predict(X_test)\n",
        "\n",
        "print(Y_preds[:10])\n",
        "print(Y_test[:10])\n",
        "\n",
        "print('Test R^2 Score : %.3f'%mlp_regressor.score(X_test, Y_test)) ## Score method also evaluates accuracy for classification models.\n",
        "print('Training R^2 Score : %.3f'%mlp_regressor.score(X_train, Y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6as5LRNgjTng",
        "colab_type": "text"
      },
      "source": [
        "### 11.2 Important Attributes of MLPRegressor\n",
        "MLPRegressor has all attributes the same as that of MLPClassifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJqR3QmDln22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Loss : \", mlp_regressor.loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3VNjTEFlxlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of Coefs : \", len(mlp_regressor.coefs_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5BA6mb5l6WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of Intercepts : \", len(mlp_regressor.intercepts_))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrP6np-kl_AN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of Iterations for Which Estimator Ran : \", mlp_regressor.n_iter_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld1_nNE_mDcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Name of Output Layer Activation Function : \", mlp_regressor.out_activation_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "yN3QOkmDCAed",
        "colab_type": "text"
      },
      "source": [
        "### 11.3 - Finetuning Model By Doing Grid Search On Various Hyperparameters. ###\n",
        "\n",
        "MLPRegressor has almost the same parameters as that of MLPClassifier.\n",
        "\n",
        "We'll below try various values for the above-mentioned hyperparameters to find the best estimator for our dataset by splitting data into 5-fold cross-validation.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "r_zlZzfcCAee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "4e33bb7d-3fc1-4864-8170-9864a5f6dd57"
      },
      "source": [
        " params = {'activation': ['relu', 'tanh', 'logistic', 'identity'],\n",
        "          'hidden_layer_sizes': list(itertools.permutations([50,100,150],2)) + list(itertools.permutations([50,100,150],3)) + [50,100,150],\n",
        "          'solver': ['adam', 'lbfgs'],\n",
        "          'learning_rate' : ['constant', 'adaptive', 'invscaling']\n",
        "         }\n",
        "\n",
        "mlp_regressor_grid = GridSearchCV(MLPRegressor(random_state=123), param_grid=params, n_jobs=-1, cv=5, verbose=5)\n",
        "mlp_regressor_grid.fit(X_train,Y_train)\n",
        "\n",
        "print('Train R^2 Score : %.3f'%mlp_regressor_grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test R^2 Score : %.3f'%mlp_regressor_grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best R^2 Score Through Grid Search : %.3f'%mlp_regressor_grid.best_score_)\n",
        "print('Best Parameters : ',mlp_regressor_grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    6.2s\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:   30.8s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=-1)]: Done 878 tasks      | elapsed: 10.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 14.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed: 18.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1796 tasks      | elapsed: 21.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1800 out of 1800 | elapsed: 21.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train R^2 Score : 0.734\n",
            "Test R^2 Score : 0.592\n",
            "Best R^2 Score Through Grid Search : 0.722\n",
            "Best Parameters :  {'activation': 'identity', 'hidden_layer_sizes': (150, 50), 'learning_rate': 'constant', 'solver': 'lbfgs'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7uTbEWCAei",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "- Scikit-Learn - Neural NetworkÂ¶\n",
        "https://coderzcolumn.com/tutorials/machine-learning/scikit-learn-sklearn-neural-network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LvqfD4BCAei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}