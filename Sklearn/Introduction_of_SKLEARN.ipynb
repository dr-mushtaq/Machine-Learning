{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction of SKLEARN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Machine-Learning/blob/master/Sklearn/Introduction_of_SKLEARN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lXFVQaIPBks",
        "colab_type": "text"
      },
      "source": [
        "# **1- What is Scikit Learn**\n",
        "\n",
        "is most popular libary of machine leanring \n",
        "Scikit learn is a library used to perform machine learning in Python. Scikit learn is an open source library which is licensed under BSD and is reusable in various contexts, encouraging academic and commercial use. It provides a range of supervised and unsupervised learning algorithms in Python. Scikit learn consists of popular algorithms and libraries. Apart from that, it also contains the following packages[2]:\n",
        "\n",
        "NumPy\n",
        "Matplotlib\n",
        "SciPy (Scientific Python)\n",
        "Scikit learn is one of the attraction where we can implement machine learning using Python. It is a free machine learning library which contains simple and efficient tools for data analysis and mining purposes[1].\n",
        "\n",
        "Scikit learn comes with sample datasets, such as iris and digits. You can import the datasets and play around with them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leMVkc3Eg9rz",
        "colab_type": "text"
      },
      "source": [
        "# **2- Prepare Data for Sklearn**\n",
        "\n",
        "**Preparing data for scikit-learn**\n",
        "- scikit-learn expects a particular structure of data:\n",
        "(samples, features)\n",
        "- Make sure that your data is atleasttwo-dimensiona\n",
        "- Make sure the rst dimension is samples\n",
        "\n",
        "**If your data is not shaped properly**\n",
        "\n",
        "Ifthe axes are swapped:\n",
        "- array.T.shape\n",
        "\n",
        "**If your data is not shaped properly**\n",
        "\n",
        "If we're missing an axis, use .reshape() :\n",
        "- array.shape\n",
        "- (10,)\n",
        "- rray.reshape([-1, 1]).shape\n",
        "- (10, 1)\n",
        "- -1 will automatically llthat axis with remaining values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EEdY_ieugBw",
        "colab_type": "text"
      },
      "source": [
        "# **3- Supervised Learning**[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Nuw1B7utjE",
        "colab_type": "text"
      },
      "source": [
        "## **3.1-Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbM5xxSau2lE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UCNyTtIu6zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# step-1: creating model class object \n",
        "model = LogisticRegression()\n",
        "# step-2: fitting training data\n",
        "model.fit(X_train, y_train)\n",
        "# step-3: using model to predict target class\n",
        "model.predict(X_test)\n",
        "# optional: using model to predict probability for each target class\n",
        "model.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FvifEogvQE2",
        "colab_type": "text"
      },
      "source": [
        "## **3.2K-Nearest Neighbors (KNN)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tet0DYR4vYf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# step-1: creating model class object \n",
        "model = KNeighborsClassifier(n = 5) \n",
        "# step-2: fitting training data\n",
        "model.fit(X_train, y_train)\n",
        "# step-3: using model to predict target class\n",
        "model.predict(X_test)\n",
        "# optional: using model to predict probability for each target class\n",
        "model.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttr-4JYf59dx",
        "colab_type": "text"
      },
      "source": [
        "## **3.3 Decision Trees Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3PAu21Q6FlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# step-1: creating model class object \n",
        "model = DecisionTreeClassifier(max_depth = 10) \n",
        "# step-2: fitting training data\n",
        "model.fit(X_train, y_train)\n",
        "# step-3: using model to predict target class\n",
        "model.predict(X_test)\n",
        "# optional: using model to predict probability for each target class\n",
        "model.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSPBahwA77QJ",
        "colab_type": "text"
      },
      "source": [
        "## **3.4 Random Forest Classifier**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbvsvi3H8IGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# step-1: creating model class object \n",
        "model = RandomForestClassifier(n_estimators = 50) \n",
        "# step-2: fitting training data\n",
        "model.fit(X_train, y_train)\n",
        "# step-3: using model to predict target class\n",
        "model.predict(X_test)\n",
        "# optional: using model to predict probability for each target class\n",
        "model.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2akIh6Pi8LXp",
        "colab_type": "text"
      },
      "source": [
        "## **3.5 Support Vector Machines (SVM)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HWCiLyG8YSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "# step-1: creating model class object \n",
        "model = SVC() \n",
        "# step-2: fitting training data\n",
        "model.fit(X_train, y_train)\n",
        "# step-3: using model to predict target class\n",
        "model.predict(X_test)\n",
        "# optional: using model to predict probability for each target class\n",
        "model.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8es9nRYg8hU6",
        "colab_type": "text"
      },
      "source": [
        "## **3.6 Naïve Bayes Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APxMf30J8oPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "# step-1: creating model class object \n",
        "model = GaussianNB() \n",
        "# step-2: fitting training data\n",
        "model.fit(X_train, y_train)\n",
        "# step-3: using model to predict target class\n",
        "model.predict(X_test)\n",
        "# optional: using model to predict probability for each target class\n",
        "model.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0t6E5SpU2E6",
        "colab_type": "text"
      },
      "source": [
        "# **4 Supervised-learning with scikit-learn** [3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rGApnBJVQM9",
        "colab_type": "text"
      },
      "source": [
        "## **4.1 Supervised Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emvYvPAgpNVq",
        "colab_type": "text"
      },
      "source": [
        "##**4.2 Exploratory data analysis**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jH5AyYYCto7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "iris=datasets.load_iris()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdjbW9ycC1u3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(iris)\n",
        "#output sklearn.dataset.base.bunch (similar to dictonary that contain keyvalue pairs )\n",
        "print(iris.keys())\n",
        "# Print the keys, we see that they are the feature name\n",
        "type(iris.data), type(iris.target)\n",
        "#(numpy.ndaray, numpy.ndarray)\n",
        "iris.data.shape\n",
        "# tell us that there 150 row and 4 column\n",
        "iris.target_names \n",
        "# arrat['setosa','versocolor','virginica'],dtype=]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-6XHQmSmy_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3b2358a4-810c-4a95-dfcc-b0270749902c"
      },
      "source": [
        "In [12]: X = iris.data\n",
        "In [13]: y = iris.target\n",
        "#Build a DataFram of the feature data and also passing column name\n",
        "In [14]: df = pd.DataFrame(X, columns=iris.feature_names)\n",
        "In [15]: print(df.head())\n",
        " "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                5.1               3.5                1.4               0.2\n",
            "1                4.9               3.0                1.4               0.2\n",
            "2                4.7               3.2                1.3               0.2\n",
            "3                4.6               3.1                1.5               0.2\n",
            "4                5.0               3.6                1.4               0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQBHDBm8nivZ",
        "colab_type": "text"
      },
      "source": [
        "**Visual EDA**\n",
        "\n",
        "Use the pandas function scatter matrix to visuliz our dataset. we pass it the our DataFram , along with our target variable as argument to the parameter c\n",
        "which stands for color ensuring that our data points in our figure will be colored by their species. we also pass a list to fig zie which specifies the size of our figure , as well as marker size and shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgR77wmeouJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "In [16]: 1_ = pd.scatter_matrix(df, c = y, figsize = [8, 8],\n",
        " ...: s=150, marker = 'D') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5z5bOuEqM9l",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1pYaLnwUmAZhoTOLIVJqg7NgfLkdNuBhT)\n",
        "\n",
        "The result is a matrix of figure, which on the diagonal are histograms of the features correspondng to the row and column. The off-Diagonal figures are scatter plots of the column features versus row features colored by the target variable. See here for example that petal and width and length are high correlated , as you may expected and that flowers are clustered according to species. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0QtEjtZ8vN5",
        "colab_type": "text"
      },
      "source": [
        "##**4.3 Numerical EDA**\n",
        "In this chapter, you'll be working with a dataset obtained from the [Machine Learning Repository ](https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records) consisting of votes made by US House of Representatives Congressmen. Your goal will be to predict their party affiliation ('Democrat' or 'Republican') based on how they voted on certain key issues. Here, it's worth noting that we have preprocessed this dataset to deal with missing values. This is so that your focus can be directed towards understanding how to train and evaluate supervised learning models. Once you have mastered these fundamentals, you will be introduced to preprocessing techniques in Chapter 4 and have the chance to apply them there yourself - including on this very same dataset!\n",
        "\n",
        "Before thinking about what supervised learning models you can apply to this, however, you need to perform Exploratory data analysis (EDA) in order to understand the structure of the data. For a refresher on the importance of EDA, check out the first two chapters of Statistical Thinking in Python (Part 1).\n",
        "\n",
        "Get started with your EDA now by exploring this voting records dataset numerically. It has been pre-loaded for you into a DataFrame called df. Use pandas' .head(), .info(), and .describe() methods in the IPython Shell to explore the DataFrame, and select the statement below that is not true."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nJsQvvEEyrL",
        "colab_type": "text"
      },
      "source": [
        "- he DataFrame has a total of 435 rows and 17 columns.\n",
        "- Except for 'party', all of the columns are of type int64.\n",
        "- The first two rows of the DataFrame consist of votes made by Republicans and the next three rows consist of votes made by Democrats.\n",
        "- **There are 17 predictor variables, or features, in this DataFrame**.\n",
        "- The target variable in this DataFrame is 'party'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eaP-kp1FGso",
        "colab_type": "text"
      },
      "source": [
        "## **4.4 Visual EDA**\n",
        "\n",
        "The Numerical EDA you did in the previous exercise gave you some very important information, such as the names and data types of the columns, and the dimensions of the DataFrame. Following this with some visual EDA will give you an even better understanding of the data. In the video, Hugo used the scatter_matrix() function on the Iris data for this purpose. However, you may have noticed in the previous exercise that all the features in this dataset are binary; that is, they are either 0 or 1. So a different type of plot would be more useful here, such as Seaborn's countplot.\n",
        "\n",
        "Given on the right is a countplot of the 'education' bill, generated from the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMAvUrieJzn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "sns.countplot(x='education', hue='party', data=df, palette='RdBu')\n",
        "plt.xticks([0,1], ['No', 'Yes'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzTIrJ0lJ8iT",
        "colab_type": "text"
      },
      "source": [
        "In sns.countplot(), we specify the x-axis data to be 'education', and hue to be 'party'. Recall that 'party' is also our target variable. So the resulting plot shows the difference in voting behavior between the two parties for the 'education' bill, with each party colored differently. We manually specified the color to be 'RdBu', as the Republican party has been traditionally associated with red, and the Democratic party with blue.\n",
        "\n",
        "It seems like Democrats voted resoundingly against this bill, compared to Republicans. This is the kind of information that our machine learning model will seek to learn when we try to predict party affiliation solely based on voting behavior. An expert in U.S politics may be able to predict this without machine learning, but probably not instantaneously - and certainly not if we are dealing with hundreds of samples!\n",
        "\n",
        "In the IPython Shell, explore the voting behavior further by generating countplots for the 'satellite' and 'missile' bills, and answer the following question: Of these two bills, for which ones do Democrats vote resoundingly in favor of, compared to Republicans? Be sure to begin your plotting statements for each figure with plt.figure() so that a new figure will be set up. Otherwise, your plots will be overlayed onto the same figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s67cZPyvKJX0",
        "colab_type": "text"
      },
      "source": [
        "- 'satellite'.\n",
        "- 'missile'.\n",
        "-**Both 'satellite' and 'missile'**\n",
        "- Neither 'satellite' nor 'missile'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JptFoh-pjAaQ",
        "colab_type": "text"
      },
      "source": [
        "#**Referenes**\n",
        "[[1] Classification Algorithms Explained in 30 Minutes](https://datamahadev.com/classification-algorithms-explained-in-30-minutes/)\n",
        "\n",
        "[[2]A Beginner’s Guide To Scikit Learn](https://medium.com/edureka/scikit-learn-machine-learning-7a2d92e4dd07)\n",
        "\n",
        "[[3] supervised-learning-with-scikit-learn](https://campus.datacamp.com/courses/supervised-learning-with-scikit-learn/classification?ex=1)\n",
        "\n",
        "[[4]datacamp-machine-learning-with-scikit-learn](https://github.com/hzitoun/datacamp-machine-learning-with-scikit-learn)"
      ]
    }
  ]
}